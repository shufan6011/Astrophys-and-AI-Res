{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNp8lXRfnhuoRt0BQOR3ggU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shufan6011/GW-Event-Detection/blob/main/Step_3_Basic_GW_Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update:\n",
        "# Event Detection by DL models come in the subsequent steps"
      ],
      "metadata": {
        "id": "XFOTmR-m3OzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "YChNQSU09Wd9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95dylknOM1YX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests, os\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Go to https://gwosc.org\n",
        "# Find info required below (GPS time & detector)\n"
      ],
      "metadata": {
        "id": "bzbKy-scjhEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOWxRKp9QYKj"
      },
      "outputs": [],
      "source": [
        "# Set GPS time:\n",
        "t_start = 1126259462.4\n",
        "t_end = 1126259462.4 # For specific events, make t_end the same as t_start\n",
        "\n",
        "# Choose detector (H1, L1, or V1)\n",
        "detector = 'H1'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3lh1EDQgU6e"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "try:\n",
        "    from gwpy.timeseries import TimeSeries\n",
        "except:\n",
        "    ! pip install -q \"gwpy==3.0.8\"\n",
        "    ! pip install -q \"matplotlib==3.9.0\"\n",
        "    ! pip install -q \"astropy==6.1.0\"\n",
        "    from gwpy.timeseries import TimeSeries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhembQ-1QYKo"
      },
      "outputs": [],
      "source": [
        "from gwosc.locate import get_urls\n",
        "url = get_urls(detector, t_start, t_end)[-1]\n",
        "\n",
        "# If an event is chosen, then its info will be shown in url\n",
        "print('Downloading: ' , url)\n",
        "fn = os.path.basename(url)\n",
        "with open(fn,'wb') as strainfile:\n",
        "    straindata = requests.get(url)\n",
        "    strainfile.write(straindata.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WB3QLymQYKq"
      },
      "outputs": [],
      "source": [
        "# Read strain data\n",
        "strain = TimeSeries.read(fn,format='hdf5.gwosc')\n",
        "\n",
        "# Examine an interval closely\n",
        "# center = int(t_start)\n",
        "# strain = strain.crop(center-0.2, center+0.1)\n",
        "\n",
        "# Extract time and strain vals\n",
        "timestamps = strain.times.value\n",
        "strain_values = strain.value\n",
        "\n",
        "# Store data in pd df\n",
        "data = pd.DataFrame({\n",
        "    'time': timestamps,\n",
        "    'strain': strain_values\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Missing Values"
      ],
      "metadata": {
        "id": "st3QjZwnPSs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing vals\n",
        "data = data.dropna()\n",
        "\n",
        "print(\"\\nMissing vals after cleaning:\")\n",
        "print(data.isnull().sum())\n"
      ],
      "metadata": {
        "id": "qgcP-cYXNKzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Noise Filtering"
      ],
      "metadata": {
        "id": "o9GWFMK9PBtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Band-pass filter function\n",
        "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    return b, a\n",
        "\n",
        "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
        "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "# Filter params\n",
        "lowcut = 20  # Low cutoff frequency (Hz)\n",
        "highcut = 500  # High cutoff frequency (Hz)\n",
        "\n",
        "# Band-pass filter strain data\n",
        "data['strain'] = bandpass_filter(data['strain'], lowcut, highcut, 4096)\n"
      ],
      "metadata": {
        "id": "zQOeTtFfNkDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Normalization"
      ],
      "metadata": {
        "id": "VZjAUoRqft9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize strain data\n",
        "scaler = StandardScaler()\n",
        "data['strain'] = scaler.fit_transform(data[['strain']])\n"
      ],
      "metadata": {
        "id": "OTmnUun1fwK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Inspection"
      ],
      "metadata": {
        "id": "qrpSAW3aPNzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect first few rows\n",
        "print(\"First few rows of data:\")\n",
        "print(data.head())\n",
        "\n",
        "# Inspect col headers\n",
        "print(\"\\nCol headers:\")\n",
        "print(data.columns)\n",
        "\n",
        "# Summary stats\n",
        "print(\"\\nSummary stats:\")\n",
        "print(data.describe())\n",
        "\n",
        "# Check for missing vals\n",
        "print(\"\\nMissing vals in each col:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Check sampling frequency\n",
        "print(f\"Sampling frequency: {strain.sample_rate} Hz\")\n",
        "fs = 4096 # Change this if sampling frequency is diff\n"
      ],
      "metadata": {
        "id": "QTyLuzDQJxfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time-Domain Features"
      ],
      "metadata": {
        "id": "KNlTwqB_dCzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_and_print_time_domain_features(data, strain_column, fs):\n",
        "    peak_amplitude = np.max(data[strain_column])\n",
        "    min_amplitude = np.min(data[strain_column])\n",
        "    print(f\"Peak Amplitude ({strain_column}): {peak_amplitude}\")\n",
        "    print(f\"Min Amplitude ({strain_column}): {min_amplitude}\")\n",
        "\n",
        "    threshold = 0.5 * peak_amplitude\n",
        "    significant_signal = data[strain_column].abs() > threshold\n",
        "    signal_duration = significant_signal.sum() * (1/fs)\n",
        "    print(f\"Signal Duration ({strain_column}): {signal_duration}s\")\n",
        "\n",
        "    signal_power = np.mean(data[strain_column]**2)\n",
        "    noise_power = np.mean(data[data[strain_column].abs() <= threshold][strain_column]**2)\n",
        "    snr = 10 * np.log10(signal_power / noise_power)\n",
        "    print(f\"Signal-to-Noise Ratio (SNR) ({strain_column}): {snr} dB\\n\")\n",
        "\n",
        "# Calc features for strain data\n",
        "print(\"Calc features for strain data: \")\n",
        "calc_and_print_time_domain_features(data, 'strain', fs)\n"
      ],
      "metadata": {
        "id": "In6iiBqadHzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Event Detection & Parameter Estimation"
      ],
      "metadata": {
        "id": "AZGf_msgdkBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_threshold(data, strain_column, factor=3):\n",
        "    noise_std = np.std(data[strain_column])\n",
        "    threshold = factor * noise_std\n",
        "    return threshold\n",
        "\n",
        "def detect_events(data, strain_column, threshold):\n",
        "    events = []\n",
        "    event_start = None\n",
        "\n",
        "    for i, strain in enumerate(data[strain_column]):\n",
        "        if abs(strain) > threshold:\n",
        "            if event_start is None:\n",
        "                event_start = i\n",
        "        else:\n",
        "            if event_start is not None:\n",
        "                event_end = i\n",
        "                events.append((event_start, event_end))\n",
        "                event_start = None\n",
        "\n",
        "    # Check if an event is ongoing at end of data\n",
        "    if event_start is not None:\n",
        "        events.append((event_start, len(data[strain_column]) - 1))\n",
        "    return events\n",
        "\n",
        "def estimate_event_params(data, strain_column, events, fs):\n",
        "    time_column = 'time'\n",
        "\n",
        "    event_params = []\n",
        "    for event in events:\n",
        "        start_idx, end_idx = event\n",
        "        event_data = data[strain_column].iloc[start_idx:end_idx]\n",
        "        peak_amplitude = np.max(np.abs(event_data))\n",
        "        duration = (end_idx - start_idx) / fs\n",
        "        event_params.append({\n",
        "            'start_time': data[time_column].iloc[start_idx],\n",
        "            'end_time': data[time_column].iloc[end_idx - 1],\n",
        "            'peak_amplitude': peak_amplitude,\n",
        "            'duration': duration\n",
        "        })\n",
        "    return event_params\n",
        "\n",
        "# Calc thresholds\n",
        "threshold = calc_threshold(data, 'strain')\n",
        "\n",
        "print(f\"Threshold: {threshold}\")\n",
        "\n",
        "# Detect events\n",
        "events = detect_events(data, 'strain', threshold)\n",
        "\n",
        "# Estimate event params\n",
        "event_params = estimate_event_params(data, 'strain', events, fs)\n",
        "\n",
        "print(\"\\nEvent Params:\")\n",
        "for param in event_params:\n",
        "    print(param)\n"
      ],
      "metadata": {
        "id": "qzXZCiAebqNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Statistical Analysis"
      ],
      "metadata": {
        "id": "gtIP5bRzduat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_event_params(event_params):\n",
        "    if not event_params:  # Check if event_params array is empty\n",
        "        return {\n",
        "            'num_events': 0,\n",
        "            'average_duration': 0,\n",
        "            'max_duration': 0,\n",
        "            'average_peak_amplitude': 0,\n",
        "            'max_peak_amplitude': 0\n",
        "        }\n",
        "\n",
        "    durations = [param['duration'] for param in event_params]\n",
        "    peak_amplitudes = [param['peak_amplitude'] for param in event_params]\n",
        "\n",
        "    summary = {\n",
        "        'num_events': len(event_params),\n",
        "        'average_duration': np.mean(durations),\n",
        "        'max_duration': np.max(durations),\n",
        "        'average_peak_amplitude': np.mean(peak_amplitudes),\n",
        "        'max_peak_amplitude': np.max(peak_amplitudes)\n",
        "    }\n",
        "    return summary\n",
        "\n",
        "# Summarize event params\n",
        "summary = summarize_event_params(event_params)\n",
        "\n",
        "print(\"\\nSummary of Event Params:\")\n",
        "print(summary)\n"
      ],
      "metadata": {
        "id": "djjYVJv3XzFh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}